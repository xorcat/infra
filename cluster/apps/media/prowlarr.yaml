---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: prowlarr
  namespace: media
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://k8s-at-home.com/charts/
      chart: prowlarr
      version: 4.4.2
      sourceRef:
        kind: HelmRepository
        name: k8s-at-home
        namespace: flux-system
      interval: 5m
  values:
    image:
      repository: ghcr.io/k8s-at-home/prowlarr
      tag: v0.4.0.1802
    env:
      TZ: "Australia/Brisbane"
    ingress:
      main:
        enabled: true
        annotations:
          cert-manager.io/cluster-issuer: "letsencrypt-production"
          traefik.ingress.kubernetes.io/router.entrypoints: "websecure"
          traefik.ingress.kubernetes.io/router.middlewares: "networking-auth-local@kubernetescrd"
        hosts:
          - host: "prowl.arr.${SECRET_INTERNAL_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - "prowl.arr.${SECRET_INTERNAL_DOMAIN}"
            secretName: prowl-tls
    persistence:
      config:
        enabled: true
        storageClass: block
        size: 5Gi
        accessMode: ReadWriteOnce
        annotations:
          helm.sh/resource-policy: "keep"
      media:
        enabled: true
        existingClaim: media
    addons:
      vpn:
        enabled: true
        # This Should be set to `wireguard`. This will set the add-on to use the default settings for Wireguard based connections.
        type: wireguard
        # If the podSecurityContext is set to run as a different user, make sure to run the Wireguard container as UID/GID 568.
        # This is required for it to be able to read certain configuration files.
        securityContext:
          runAsUser: 568
          runAsGroup: 568
        env:
          # Enable a killswitch that kills all trafic when the VPN is not connected
          KILLSWITCH: "true"
        configFile: "${SECRET_VPN_CONFIG}"
    resources:
      requests:
        memory: 100Mi
        cpu: 100m
      limits:
        memory: 500Mi
    prometheus:
      podMonitor:
        enabled: true
        interval: 10m
        scrapeTimeout: 2m
        labels:
          app.kubernetes.io/component: monitoring
    podSecurityContext:
      runAsUser: 1001
      runAsGroup: 1001
      fsGroup: 1001
